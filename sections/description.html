<div class="container">
  <div class="row me-row content-ct">
      <h2 class="row-title">About</h2>
      <div class="col-md feature">
        Human-agent teamwork is no longer a topic of the future. With the increasing prominence of human-agent interaction in hybrid teams 
        in diverse industries, several challenges arise that need to be addressed carefully. One of these challenges is understanding how trust
        is defined and how it functions in Human-agent teams. Psychological literature suggests that within human teams, team members rely 
        on trust to make decisions and to be willing to rely on their team. Besides that, the multi-agent systems (MAS) community has been 
        adopting trust mechanisms to support decision-making of the agents regarding their peers and for delegating tasks to agents. 
        Finally, in the last couple of years, researchers have been focusing on how humans trust AI agents and how such systems can be trustworthy.
        But when we think of a team composed of both humans and agents, with recurrent (or not) interactions, how do these all come together?

        With these premises, we are organizing the MULTITTRUST 3.0 workshop, which is part of the 
        <a href="https://hhai-conference.org/2024/"  target="_blank" >HHAI conference 2024</a>. This is the third edition of the original 
        <a href="https://multittrust.github.io/"  target="_blank" >MULTITRUST</a> workshop at the <a href="https://multittrust.github.io/"  target="_blank" >HHAI 2023 Conference in Munich</a>
        Our goal is to motivate the conversation across the different fields and domains. Together, we may shape the road to 
        answer these questions and more.
      </div>
    </div>
</div>



